# Guide Optimisation et Performance - Morpheus CO‚ÇÇ

## Vue d'ensemble

Le module d'optimisation de Morpheus am√©liore la vitesse, la fiabilit√© et l'efficacit√© de votre syst√®me. Caching intelligent, requ√™tes optimis√©es et limiteurs de d√©bit garantissent une exp√©rience fluide m√™me sous forte charge.

## Capacit√©s principales

### 1. **Caching intelligent**
R√©duction drastique de latence

- Cache distribu√© multi-niveaux
- TTL adapt√©s (temps de fra√Æcheur)
- Invalidation intelligente
- Hit rate > 85% en usage normal

### 2. **Optimisation requ√™tes**
R√©duction charge base donn√©es

- Index sur colonnes fr√©quentes
- Requ√™tes param√©tr√©es
- Pagination automatique
- Compression donn√©es

### 3. **Limitation de d√©bit (Rate Limiting)**
Protection contre surcharge

- Quotas par utilisateur
- Quotas globaux syst√®me
- Throttling progressif
- R√©cup√©ration rapide

### 4. **Monitoring en temps r√©el**
Visibilit√© compl√®te performance

- Dashboard temps r√©el
- Alertes automatiques
- Historique d√©taill√©
- Recommandations optimisation

## Guide d'utilisation

### Acc√©der au module Performance

1. **√Ä partir de l'admin**
   ```
   Menu ‚Üí Administration ‚Üí Performance
   ou: /admin/performance
   ```

2. **Dashboard principal**
   ```
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ  Performance Syst√®me Morpheus        ‚îÇ
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ                                      ‚îÇ
   ‚îÇ Temps r√©el ‚îÇ Historique ‚îÇ Config    ‚îÇ
   ‚îÇ                                      ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ```

### Monitoring en temps r√©el

1. **M√©triques cl√©s**
   ```
   Cache
   ‚îú‚îÄ Hit rate: 87.5% ‚úì Excellent
   ‚îú‚îÄ Taille: 245 MB / 500 MB (49%)
   ‚îú‚îÄ Items cach√©s: 15,430
   ‚îî‚îÄ TTL moyen: 8.3 heures
   
   Requ√™tes API
   ‚îú‚îÄ Requ√™tes/sec: 124
   ‚îú‚îÄ Latence m√©diane: 45ms
   ‚îú‚îÄ Latence P95: 180ms
   ‚îú‚îÄ Erreurs/min: 0
   ‚îî‚îÄ Uptime: 99.98%
   
   Base donn√©es
   ‚îú‚îÄ Connexions actives: 23 / 100
   ‚îú‚îÄ Requ√™tes/sec: 456
   ‚îú‚îÄ Requ√™tes lentes (> 1s): 2 (0.3%)
   ‚îî‚îÄ Derni√®re maintenance: 5 jours
   
   Syst√®me
   ‚îú‚îÄ Charge CPU: 32% (faible)
   ‚îú‚îÄ M√©moire RAM: 4.2 GB / 8 GB (52%)
   ‚îú‚îÄ Disque: 128 GB / 256 GB (50%)
   ‚îî‚îÄ Temp√©rature: 48¬∞C (normal)
   ```

2. **Interpr√©tation des m√©triques**
   ```
   ‚úì BON:
   - Cache hit rate > 80%
   - Latence P95 < 200ms
   - Erreurs < 0.1%
   - CPU/M√©moire < 70%
   
   ‚ö†Ô∏è √Ä SURVEILLER:
   - Cache hit rate 60-80%
   - Latence P95 200-500ms
   - Erreurs 0.1-1%
   - CPU/M√©moire 70-85%
   
   üî¥ PROBL√àME:
   - Cache hit rate < 60%
   - Latence P95 > 500ms
   - Erreurs > 1%
   - CPU/M√©moire > 85%
   ```

### Configuration du caching

1. **Onglet "Configuration cache"**
   ```
   Param√®tres globaux:
   
   [ ] Cache activ√© (‚úì Activ√©)
   [ ] Cache distribu√© (‚úì Redis)
   
   Taille maximale: [500 MB]
   Politique √©viction: [LRU ‚ñº]
   
   Dur√©e de vie par d√©faut:
   ‚îú‚îÄ Sensor data: [3600 s] (1 heure)
   ‚îú‚îÄ Dashboard: [1800 s] (30 min)
   ‚îú‚îÄ Analytics: [7200 s] (2 heures)
   ‚îî‚îÄ User settings: [86400 s] (24h)
   
   [Sauvegarder]
   ```

2. **Invalidation cache**
   ```
   Invalidation manuelle:
   
   Tout le cache:
   [Vider compl√®tement le cache]
   
   Cache s√©lectif:
   ‚òë Sensor: Bureau-101
   ‚òë Dashboard: Production
   ‚òê Analytics cache
   
   [Invalider s√©lection]
   
   Cache stats d√©taill√©es:
   Cl√©s en cache: 15,430
   M√©moire utilis√©e: 245 MB
   Requ√™te les plus cach√©es: (liste)
   ```

3. **Configurations sp√©cialis√©es**
   ```
   Cache par type de donn√©es:
   
   Lectures capteur:
   ‚îú‚îÄ TTL court (5 min): Donn√©es temps r√©el
   ‚îú‚îÄ TTL moyen (1h): Moyennes horaires
   ‚îî‚îÄ TTL long (24h): Graphiques journ√©e
   
   Analytics/Pr√©dictions:
   ‚îú‚îÄ TTL tr√®s long (48h): Mod√®les ML
   ‚îú‚îÄ TTL court (5 min): Pr√©dictions actuelles
   ‚îî‚îÄ Invalider avant chaque pr√©diction nouvelle
   
   Donn√©es utilisateur:
   ‚îú‚îÄ TTL court (15 min): Permissions
   ‚îú‚îÄ TTL moyen (1h): Pr√©f√©rences
   ‚îî‚îÄ Invalider √† chaque changement
   ```

### Optimisation des requ√™tes

1. **Onglet "Requ√™tes"**
   ```
   Top 10 requ√™tes les plus co√ªteuses:
   
   Rang ‚îÇ Requ√™te        ‚îÇ Hits ‚îÇ Temps moy ‚îÇ Optimisation
   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   1.   ‚îÇ GET /readings  ‚îÇ 2.5k ‚îÇ 245ms    ‚îÇ ‚ö†Ô∏è Index manquant
   2.   ‚îÇ GET /sensors   ‚îÇ 4.1k ‚îÇ 85ms     ‚îÇ ‚úì Optimal
   3.   ‚îÇ POST /export   ‚îÇ 156  ‚îÇ 1.2s     ‚îÇ ‚ö†Ô∏è √Ä parall√©liser
   4.   ‚îÇ GET /analytics ‚îÇ 856  ‚îÇ 520ms    ‚îÇ ‚ö†Ô∏è Cache d√©sactiv√©
   5.   ‚îÇ DELETE /token  ‚îÇ 234  ‚îÇ 45ms     ‚îÇ ‚úì Optimal
   
   Requ√™tes √† probl√®me:
   
   1Ô∏è‚É£ GET /readings - Acc√®s base donn√©es lent
   
   Diagnostic:
   ‚îú‚îÄ SELECT * readings WHERE... (2.3s query)
   ‚îú‚îÄ Index: readings_sensor_id existe
   ‚îú‚îÄ Probl√®me: WHERE clause sur plusieurs colonnes
   
   Recommandations:
   ‚úì Cr√©er index compos√© (sensor_id, timestamp)
   ‚úì Limiter SELECT (nombre lignes)
   ‚úì Ajouter LIMIT si top-N query
   ‚úì Utiliser cache (readings changent lentement)
   
   Impact estim√©:
   Before: 245ms ‚Üí After: 45ms
   Am√©lioration: -82% ‚úì Gain significatif
   
   [Impl√©menter optimisation]
   ```

2. **Slow Query Log**
   ```
   Requ√™tes lentes (> 1 sec) derni√®res 24h:
   
   2024-01-15 14:32 - Duration: 3.2s
   Query: SELECT DISTINCT readings.sensor_id, ...
   FROM readings
   JOIN sensors ON...
   WHERE timestamp BETWEEN '2024-01-01' AND '2024-01-15'
   GROUP BY sensor_id
   ORDER BY AVG(co2_ppm)
   
   Probl√®me: Sans index GROUP BY
   Cause: Scan table compl√®te 1.5M rows
   
   Fix recommand√©e:
   CREATE INDEX idx_readings_sensor_timestamp
   ON readings(sensor_id, timestamp)
   
   R√©sultat estim√©: 3.2s ‚Üí 0.4s
   ```

### Limitation de d√©bit (Rate Limiting)

1. **Onglet "Rate Limiting"**
   ```
   Politiques actuelles:
   
   Utilisateur standard:
   ‚îú‚îÄ Requ√™tes: 1,000 / heure
   ‚îú‚îÄ Simultan√©es: 10
   ‚îú‚îÄ Export: 5 / jour
   ‚îî‚îÄ Status: ‚úì Normal
   
   Plan Enterprise:
   ‚îú‚îÄ Requ√™tes: Illimit√©
   ‚îú‚îÄ Simultan√©es: 50
   ‚îî‚îÄ Export: Illimit√©
   
   Global:
   ‚îú‚îÄ Requ√™tes syst√®me: 100,000 / heure
   ‚îú‚îÄ Connexions DB: 100 max
   ‚îî‚îÄ Load CPU: Throttle si > 90%
   
   [Modifier politiques]
   ```

2. **Gestion des utilisateurs en limite**
   ```
   Utilisateurs actuellement throttl√©s:
   
   user@exemple.com
   ‚îú‚îÄ Limite: 1,000 req/h
   ‚îú‚îÄ Usage: 987 requ√™tes
   ‚îú‚îÄ % limite: 98.7% ‚ö†Ô∏è
   ‚îú‚îÄ Requ√™te √©chouera dans: 12 min
   ‚îî‚îÄ Actions:
      [Augmenter limite] [Contacter support]
   
   Historique throttling (7 jours):
   ‚îú‚îÄ Jours avec throttle: 2
   ‚îú‚îÄ Requ√™tes rejet√©es: 127
   ‚îî‚îÄ Raison: Ex√©cution massive requ√™tes
   ```

3. **Whitelisting/Exceptions**
   ```
   Requ√™tes d'exception:
   
   API d'import massive:
   ‚îú‚îÄ Utilisateur: integration@client.com
   ‚îú‚îÄ Limite: 10,000 requ√™tes/jour
   ‚îú‚îÄ Raison: Synchronisation syst√®me externe
   ‚îú‚îÄ D√©but: 2024-01-15
   ‚îî‚îÄ Fin: Permanent jusqu'√† r√©vocation
   
   Batch processing scientifique:
   ‚îú‚îÄ Utilisateur: research@universit√©.edu
   ‚îú‚îÄ Limite: 50,000 requ√™tes/jour
   ‚îú‚îÄ Raison: √âtude donn√©es 2023
   ‚îú‚îÄ D√©but: 2024-01-01
   ‚îî‚îÄ Fin: 2024-03-31
   
   [Ajouter nouvelle exception]
   ```

## Optimisations par sc√©nario

### Sc√©nario 1: Forte charge - Nombreux utilisateurs

```
Probl√®me: Syst√®me ralentit aux heures de pointe (12-14h)

Diagnostic:
‚îú‚îÄ Utilisateurs concurrents: 500+ ‚Üí Pics
‚îú‚îÄ Requ√™tes API: 2000/sec
‚îú‚îÄ Cache hit rate chute √† 45%
‚îî‚îÄ Latence P95: 800ms

Optimisations appliqu√©es:

1. CACHE
   ‚îú‚îÄ TTL augment√©: 3min ‚Üí 5min
   ‚îú‚îÄ Pr√©calc dashboards hors-pics
   ‚îî‚îÄ Compression donn√©es cache
   Impact: Hit rate 45% ‚Üí 75%

2. REQU√äTES
   ‚îú‚îÄ Pagination forc√©e (max 1000 rows)
   ‚îú‚îÄ Ajout indexes sur colonnes filtr√©es
   ‚îú‚îÄ Asynchrone pour requ√™tes lentes
   ‚îî‚îÄ Webhook vs polling r√©ductions
   Impact: Latence P95 800ms ‚Üí 200ms

3. DATABASE
   ‚îú‚îÄ Archivage donn√©es > 2 ans
   ‚îú‚îÄ Table partitioning par date
   ‚îî‚îÄ Read replicas pour analytics
   Impact: Requ√™tes 2.3s ‚Üí 0.4s

4. RATE LIMITING
   ‚îú‚îÄ Throttle progressif > 80% quota
   ‚îú‚îÄ Priorit√© API production vs debug
   ‚îî‚îÄ Queue requ√™tes non-critiques
   Impact: Moins rejets d'erreur

R√©sultat:
Before: Latence 800ms, Erreurs 2.5%
After: Latence 150ms, Erreurs 0.1%
Satisfaction utilisateurs: ‚Üë 35%
```

### Sc√©nario 2: Beaucoup de petites requ√™tes

```
Probl√®me: 50,000 requ√™tes/jour de petits exports

Diagnostic:
‚îú‚îÄ Chaque export = 5-10 requ√™tes DB
‚îú‚îÄ Beaucoup de connexion overhead
‚îú‚îÄ Cache inefficace (requ√™tes si diff√©rentes)

Optimisations:

1. BATCH APIS
   ‚îú‚îÄ Endpoint /api/batch pour requ√™tes multiples
   ‚îú‚îÄ Unique connexion DB pour tout batch
   ‚îî‚îÄ Une r√©ponse JSON pour 50 requ√™tes
   Impact: 50 requ√™tes ‚Üí 1 requ√™te

2. GRAPHQL (Alternative)
   ‚îú‚îÄ Client sp√©cifie donn√©es n√©cessaires
   ‚îú‚îÄ Z√©ro overfetching
   ‚îî‚îÄ 40% r√©duction data transfer
   Impact: Bande passante -40%

3. COMPRESSION
   ‚îú‚îÄ GZIP HTTP automatique
   ‚îú‚îÄ JSON compress√© au repos
   ‚îî‚îÄ Delta sync (juste changements)
   Impact: Taille r√©ponse -60%

R√©sultat:
Before: 50,000 requ√™tes/jour, 2GB data
After: 5,000 requ√™tes, 500MB data
R√©duction 90% charge API
```

### Sc√©nario 3: Requ√™tes analytiques lourdes

```
Probl√®me: Analytics/ML requ√™tes 30+ secondes

Diagnostic:
‚îú‚îÄ Requ√™tes sur 1-2 ans historique
‚îú‚îÄ Agr√©gations multiples
‚îú‚îÄ Pas de cache (r√©sultats trop vari√©s)

Optimisations:

1. MATERIALIZED VIEWS
   ‚îú‚îÄ Pr√©-calculer agr√©gations standards
   ‚îú‚îÄ Mise √† jour nuit (hors-pics)
   ‚îî‚îÄ Queries 30s ‚Üí 0.5s
   Impact: -98% latence

2. DATA WAREHOUSE
   ‚îú‚îÄ OLAP vs OLTP (s√©paration)
   ‚îú‚îÄ Agr√©gation par jour/mois
   ‚îî‚îÄ Indexation columnaire
   Impact: Requ√™tes 20x plus rapides

3. CACHING S√âMANTIQUE
   ‚îú‚îÄ Cache par requ√™te type
   ‚îÇ  (pas requ√™te exacte)
   ‚îú‚îÄ Servir approximation rapidement
   ‚îî‚îÄ D√©tail dans background
   Impact: Instant feedback utilisateur

R√©sultat:
Before: Analytiques 30s, UX bloqu√©e
After: Instantan√© (cache) + d√©tail 5s
Users heureux, syst√®me responsive
```

## D√©pannage

### "Syst√®me lent aux heures de pointe"
```
V√©rifiez:
1. Cache hit rate (doit √™tre > 80%)
   ‚Üí Si < 80%: Augmenter TTL ou pr√©-remplir

2. Requ√™tes lentes (slow query log)
   ‚Üí Ajouter index sur WHERE/JOIN colonnes
   
3. Charge syst√®me
   ‚Üí CPU > 80%: R√©duire threads/connexions
   ‚Üí RAM > 85%: R√©duire cache size
   ‚Üí Disque IO: Archiver vieilles donn√©es

4. Utilisateurs probl√©matiques
   ‚Üí Identifier top consumers
   ‚Üí V√©rifier requ√™tes inefficaces
   ‚Üí Leur proposer optimisation
```

### "Cache pas efficace malgr√© TTL long"
```
Raisons possibles:
‚Üí Cl√©s cache trop vari√©es (pas r√©utilis√©es)
‚Üí TTL pas assez long
‚Üí Invalidations trop fr√©quentes
‚Üí Pattern acc√®s pas cacheable

Diagnos:
GET /admin/cache/stats ‚Üí Voir hitrate par cl√©
Si hitrate < 30% sur cl√©:
  ‚Üí Augmenter TTL
  ‚Üí Ou accepter pas cacheable

Exemple:
- /readings?sensor=123&start=1/1&end=1/31
  ‚Üí TTL 24h car donn√©es fig√©es

- /readings?sensor=123&limit=latest
  ‚Üí TTL 1min (donn√©es changent constamment)
```

### "Rate limiting rejette requ√™tes l√©gitimes"
```
V√©rifiez:
1. Quota utilisateur appropri√©?
   GET /api/quota/user
   Si insuffisant: Upgrade plan ou exception

2. Distribu√© les requ√™tes dans le temps
   Au lieu de: 1,000 req en 1 seconde
   Essayez: Spread sur 60 secondes
   
3. Batch APIs pour r√©duire nombre requ√™tes
   Voir endpoint /api/batch
   
4. Cache c√¥t√© client
   √âvitez re-requ√™tes donn√©es identiques
```

## Bonnes pratiques

1. **Monitoring r√©gulier**
   - V√©rifiez dashboard chaque semaine
   - Alertes si hit rate < 80%
   - Alertes si P95 latence > 200ms

2. **Tuning continu**
   - Une optimisation √† la fois
   - Mesurer avant/apr√®s
   - Documenter changements

3. **Caching strat√©gique**
   - Cache donn√©es stables longtemps
   - TTL court pour donn√©es changeantes
   - Invalider au besoin, pas trop souvent

4. **Archivage r√©gulier**
   - Donn√©es > 3 ans: Archive
   - Lib√®re ressources production
   - Analyse historique toujours possible

5. **Planning capacit√©**
   - Croissance 30%/an moyenne
   - Upgrade mat√©riel avant saturation
   - Monitor trends long-terme

## API Performance

```bash
# Statistiques caching
GET /api/admin/performance/cache/stats
Response: {
    "hit_rate": 0.875,
    "size_bytes": 245000000,
    "items_cached": 15430,
    "avg_ttl_seconds": 29880
}

# Requ√™tes lentes
GET /api/admin/performance/slow-queries?limit=10

# Configuration cache
PATCH /api/admin/performance/cache/config
{
    "ttl_seconds": 3600,
    "max_size_bytes": 500000000
}

# Rate limit status
GET /api/admin/performance/rate-limit/status/{user_id}
```

## Prochaines √©tapes

- [D√©pannage avanc√©](TROUBLESHOOTING_FR.md)
- [Architecture syst√®me](ARCHITECTURE_FR.md)
- [Upgrade/Migration guide](UPGRADE_FR.md)
- [Support technique](https://support.morpheus.io)

---

*Pour assistance performance, contactez [support.morpheus.io/perf](https://support.morpheus.io)*
